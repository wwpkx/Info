---
mindmap-plugin: basic
---

# 多元函数微分

## 偏导数
- $y固定在y_0, x在x_0处的增量 \Delta x,则函数的增量为: f(x_0+\Delta x, y_0) - f(x_0, y_0)$
- $记作：\frac{\partial f}{\partial x} ,f_x(x_0,y_0)$

## 全微分
- $\Delta z = f(x+\Delta x, y+\Delta y)-f(x,y) \newline \quad\;\;= A\Delta x +B\Delta y + o(\rho ) \;\; 其中 \rho = \sqrt{(\Delta z)^2+(\Delta y)^2}$
- $dz = A\Delta x + \, B\Delta y$
- $dz   = f'_x(x, \, y)dx + f'_y(x, \, y)dy$

## 方向导数 和 梯度
- $f(x, y)在 P_0(x_0,y_0) 处沿方向 l 的 方向导数$
    - $f(x,y)-f(x_0,y_0)=f(x_0+tcos\alpha , y_0+tcos\beta )-f(x_0,y_0)$
    - $\frac{\partial f}{\partial l} |_{(x_0, y_0)}=f'_x(x, \, y)cos\alpha   + f'_y(x, \, y)cos\beta$
- 梯度
    - $\bigtriangledown f(x_0, y_0) = gradf(x_0, y_0) = (f'_x(x_0, y_0),f'_y(x_0, y_0))$
- 梯度与方向导数的关系
    - $当 \theta =0，方向\overrightarrow{e_l}与梯度grad(x_0,y_0)方向一致，方向导数取到最大值,且\frac{\partial f}{\partial l}|_{(x_0,y_0)} = |grad f(x_0,y_0)|$
    - $当 \theta =\pi，方向\overrightarrow{e_l} 与梯度grad(x_0,y_0)方向相反，方向导数取到最小值,且\frac{\partial f}{\partial l}|_{(x_0,y_0)} = -|grad f(x_0,y_0)|$
    - $当 \theta =\frac{\pi}{2}，方向\overrightarrow{e_l} 与梯度grad(x_0,y_0)方向正交，方向导数为0,且\frac{\partial f}{\partial l}|_{(x_0,y_0)} = 0$
- 梯度下降算法
    - 代价函数（根据梯度下降）--> 预测函数
    - 初始值
    - 梯度下降算法 = 学习率 * 导数

## 极值
- $条件1:f_x(x_0, y_0)=f_y(x_0, y_0)=0$
- $条件2:A = f{_x}{_x} (x_0, y_0),B = f{_x}{_y} (x_0, y_0),C = f{_y}{_y} (x_0, y_0)$
- $结论1:AC-B^2>0时 f(x_0,y_0) 为极值, 且A<0极大, A>0极小$
- $结论2:AC-B^2<0时 f(x_0,y_0) 不是极值$
- $结论3:AC-B^2=0时 f(x_0,y_0) 可能是极值，也可能不是极值$

## 拉格朗日乘数法(约束条件下求极值)
- 主要用于解决约束优化问题
- 基本思想：通过引入拉格朗日乘子来将含有n个变量和k个约束条件的约束优化问题转化为含有（n+k）个变量的无约束优化问题
- 拉格朗日乘子背后的数学意义是其为约束方程梯度线性组合中每个向量的系数。
- 定义
    - $求函数z=f(x,y)在满足\varphi(x,y)=0下的条件$
    - $可以转化为函数F(x,y, \lambda)=f(x,y)+\lambda \varphi(x,y) 的无条件极值问题$